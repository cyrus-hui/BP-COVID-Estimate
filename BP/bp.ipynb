{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "  nor_data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "  return nor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find10(ecg_p, ppg_peaks):\n",
    "  ecg_head = []\n",
    "  ecg_tail = []\n",
    "  ppg_head = []\n",
    "  ppg_tail = []\n",
    "  i = 1\n",
    "  j = 1\n",
    "  while len(ecg_head) < 10:\n",
    "    curr_pat = ppg_peaks[i] - ecg_p[j]\n",
    "    if ppg_peaks[i] > ecg_p[j]  > ppg_peaks[i - 1]:\n",
    "      if 65 < curr_pat < 125:\n",
    "        ecg_head.append(ecg_p[j])\n",
    "        ppg_head.append(ppg_peaks[i])\n",
    "      i = i + 1\n",
    "      j = j + 1\n",
    "    elif ppg_peaks[i] == ecg_p[j] or ppg_peaks[i - 1] == ecg_p[j]:\n",
    "      i = i + 1\n",
    "      j = j + 1\n",
    "    elif ecg_p[j] < ppg_peaks[i - 1]:\n",
    "      j = j + 1\n",
    "    else:\n",
    "      i = i + 1\n",
    "\n",
    "\n",
    "  i = -2\n",
    "  j = -2\n",
    "\n",
    "  while len(ecg_tail) < 10:\n",
    "    curr_pat = ppg_peaks[i] - ecg_p[j]\n",
    "    if ppg_peaks[i] > ecg_p[j] > ppg_peaks[i - 1]:\n",
    "      if 65 < curr_pat < 125:\n",
    "        ecg_tail.append(ecg_p[j])\n",
    "        ppg_tail.append(ppg_peaks[i])\n",
    "      i = i - 1\n",
    "      j = j - 1\n",
    "    elif ppg_peaks[i] == ecg_p[j] or ppg_peaks[i - 1] == ecg_p[j]:\n",
    "      i = i - 1\n",
    "      j = j - 1\n",
    "    elif ppg_peaks[i] < ecg_p[j]:\n",
    "      j = j - 1\n",
    "    else:\n",
    "      i = i - 1\n",
    "  \n",
    "  return ecg_head, ecg_tail, ppg_head, ppg_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find10min(ecg_p, ppg_min):\n",
    "  ecg_head = []\n",
    "  ecg_tail = []\n",
    "  ppg_head = []\n",
    "  ppg_tail = []\n",
    "  i = 1\n",
    "  j = 1\n",
    "  while len(ecg_head) < 10:\n",
    "    curr_pat = ppg_min[i] - ecg_p[j]\n",
    "    if ppg_min[i] > ecg_p[j]  > ppg_min[i - 1]:\n",
    "      if 125 < curr_pat < 200:\n",
    "        ecg_head.append(ecg_p[j])\n",
    "        ppg_head.append(ppg_min[i])\n",
    "      i = i + 1\n",
    "      j = j + 1\n",
    "    elif ppg_min[i] == ecg_p[j] or ppg_min[i - 1] == ecg_p[j]:\n",
    "      i = i + 1\n",
    "      j = j + 1\n",
    "    elif ecg_p[j] < ppg_min[i - 1]:\n",
    "      j = j + 1\n",
    "    else:\n",
    "      i = i + 1\n",
    "\n",
    "\n",
    "  i = -2\n",
    "  j = -2\n",
    "\n",
    "  while len(ecg_tail) < 10:\n",
    "    curr_pat = ppg_min[i] - ecg_p[j]\n",
    "    if ppg_min[i] > ecg_p[j] > ppg_min[i - 1]:\n",
    "      if 125 < curr_pat < 200:\n",
    "        ecg_tail.append(ecg_p[j])\n",
    "        ppg_tail.append(ppg_min[i])\n",
    "      i = i - 1\n",
    "      j = j - 1\n",
    "    elif ppg_min[i] == ecg_p[j] or ppg_min[i - 1] == ecg_p[j]:\n",
    "      i = i - 1\n",
    "      j = j - 1\n",
    "    elif ppg_min[i] < ecg_p[j]:\n",
    "      j = j - 1\n",
    "    else:\n",
    "      i = i - 1\n",
    "  \n",
    "  return ecg_head, ecg_tail, ppg_head, ppg_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_record = []\n",
    "pat_start = []\n",
    "pat_end = []\n",
    "\n",
    "filename = \"/\"\n",
    "data = pd.read_csv(filename).values\n",
    "record = data[:, 0]\n",
    "bp_sys_start = data[:, 6]\n",
    "bp_sys_end = data[:, 7]\n",
    "bp_dia_start = data[:, 8]\n",
    "bp_dia_end = data[:, 9]\n",
    "hr1_start = data[:, 10]\n",
    "hr1_end = data[:, 11]\n",
    "hr2_start = data[:, 12]\n",
    "hr2_end = data[:, 13]\n",
    "spo2_start = data[:, 14]\n",
    "spo2_end = data[:, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/\"\n",
    "csv_files = os.listdir(folder_path)\n",
    "csv_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in csv_files:\n",
    "    if filename.endswith('.csv'):\n",
    "        \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        data = pd.read_csv(file_path).values\n",
    "        time = data[:, 0]\n",
    "        ecg = data[:, 1]\n",
    "        ecg_peaks = data[:,2]\n",
    "        ppg = data[:, 3]\n",
    "\n",
    "        filename = filename [:-4]\n",
    "        pat_record.append(filename)\n",
    "\n",
    "        nor_ecg = normalize(ecg)\n",
    "        nor_ppg = normalize(ppg)\n",
    "        ecg_p = []\n",
    "        ppg_peaks, _ = find_peaks(nor_ppg, distance = 150)\n",
    "\n",
    "        for i in range(len(time)):\n",
    "          if ecg_peaks[i] == 1:\n",
    "            ecg_p.append(i)\n",
    "        \n",
    "        ecg_head, ecg_tail, ppg_head, ppg_tail = find10(ecg_p, ppg_peaks)\n",
    "\n",
    "        pat_head = []\n",
    "        pat_tail = []\n",
    "        for i in range(len(ecg_head)):\n",
    "          pat_head.append((ppg_head[i] - ecg_head[i]) * 2)\n",
    "          pat_tail.append((ppg_tail[i] - ecg_tail[i]) * 2) \n",
    "        pat_head_avg = np.average(pat_head)\n",
    "        pat_tail_avg = np.average(pat_tail)\n",
    "        \n",
    "        pat_start.append(pat_head_avg)\n",
    "        pat_end.append(pat_tail_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = []\n",
    "hr1 = []\n",
    "hr2 = []\n",
    "spo2 = []\n",
    "bp_sys = []\n",
    "bp_dia = []\n",
    "record_track = []\n",
    "for i in range(len(pat_record)):\n",
    "  for j in range(len(record)):\n",
    "    if pat_record[i] == record[j] and record[j] not in record_track:\n",
    "      record_track.append(record[j])\n",
    "      \n",
    "      pat.append(pat_start[i])\n",
    "      bp_sys.append(bp_sys_start[j])\n",
    "      bp_dia.append(bp_dia_start[j])\n",
    "      hr1.append(hr1_start[j])\n",
    "      hr2.append(hr2_start[j])\n",
    "      spo2.append(spo2_start[j])\n",
    "\n",
    "      pat.append(pat_end[i])\n",
    "      bp_sys.append(bp_sys_end[j])\n",
    "      bp_dia.append(bp_dia_end[j])\n",
    "      hr1.append(hr1_end[j])\n",
    "      hr2.append(hr2_end[j])\n",
    "      spo2.append(spo2_end[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression (SBP) - MAE: 12.194958367983222, STD: 15.362465165513994, R^2: -0.07629090784649994\n",
      "LinearRegression (DBP) - MAE: 7.723470649973286, STD: 9.284661899394683, R^2: 0.09838866932509993\n",
      "DecisionTreeRegressor (SBP) - MAE: 9.814814814814815, STD: 13.549178828016856, R^2: 0.15269653720168463\n",
      "DecisionTreeRegressor (DBP) - MAE: 5.555555555555555, STD: 7.412775832428641, R^2: 0.41857836108966573\n",
      "SVR (SBP) - MAE: 11.27363598082059, STD: 15.164075821995146, R^2: -0.01792014518225149\n",
      "SVR (DBP) - MAE: 7.647848491491745, STD: 8.901675966992904, R^2: 0.15907426148356618\n",
      "AdaBoostRegressor (SBP) - MAE: 8.839045213539205, STD: 10.91772125871851, R^2: 0.41857699119327363\n",
      "AdaBoostRegressor (DBP) - MAE: 5.475052375243784, STD: 6.886578882809079, R^2: 0.4581234885790396\n",
      "RandomForestRegressor (SBP) - MAE: 8.358518518518519, STD: 11.284484048768629, R^2: 0.40302949461862414\n",
      "RandomForestRegressor (DBP) - MAE: 5.316666666666667, STD: 6.586162448836889, R^2: 0.5186412857064078\n"
     ]
    }
   ],
   "source": [
    "df_pat = np.array(pat)\n",
    "sbp = np.array(bp_sys)\n",
    "dbp = np.array(bp_dia)\n",
    "heart_rate1 = np.array(hr1)\n",
    "heart_rate2 = np.array(hr2)\n",
    "df_spo2 = np.array(spo2)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'HR1': heart_rate1,\n",
    "    'HR2': heart_rate2,\n",
    "    'SPO2': df_spo2,\n",
    "    'PAT': pat,\n",
    "    'SBP': sbp,\n",
    "    'DBP': dbp\n",
    "})\n",
    "\n",
    "# Features and targets\n",
    "X = df[['HR1', 'HR2', 'SPO2', 'PAT']]\n",
    "\n",
    "y_sbp = df['SBP']\n",
    "y_dbp = df['DBP']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train_sbp, y_test_sbp = train_test_split(X, y_sbp, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train_dbp, y_test_dbp = train_test_split(X, y_dbp, test_size=0.2, random_state=42)\n",
    "\n",
    "# if X_train.ndim == 1:\n",
    "#   X_train = X_train.reshape(-1, 1)\n",
    "\n",
    "# if X_test.ndim == 1:\n",
    "#   X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "# Standardizing the features (important for SVM)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Function to evaluate and print results for a target\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, target_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    res = y_test - y_pred\n",
    "    std = np.std(res)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{model.__class__.__name__} ({target_name}) - MAE: {mae}, STD: {std}, R^2: {r2}\")\n",
    "\n",
    "# Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "evaluate_model(lin_reg, X_train, y_train_sbp, X_test, y_test_sbp, \"SBP\")\n",
    "evaluate_model(lin_reg, X_train, y_train_dbp, X_test, y_test_dbp, \"DBP\")\n",
    "\n",
    "# Decision Tree\n",
    "dec_tree = DecisionTreeRegressor()\n",
    "evaluate_model(dec_tree, X_train, y_train_sbp, X_test, y_test_sbp, \"SBP\")\n",
    "evaluate_model(dec_tree, X_train, y_train_dbp, X_test, y_test_dbp, \"DBP\")\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVR()\n",
    "evaluate_model(svm, X_train_scaled, y_train_sbp, X_test_scaled, y_test_sbp, \"SBP\")\n",
    "evaluate_model(svm, X_train_scaled, y_train_dbp, X_test_scaled, y_test_dbp, \"DBP\")\n",
    "\n",
    "# AdaBoost\n",
    "ada_boost = AdaBoostRegressor()\n",
    "evaluate_model(ada_boost, X_train, y_train_sbp, X_test, y_test_sbp, \"SBP\")\n",
    "evaluate_model(ada_boost, X_train, y_train_dbp, X_test, y_test_dbp, \"DBP\")\n",
    "\n",
    "# Random Forest\n",
    "rand_forest = RandomForestRegressor()\n",
    "evaluate_model(rand_forest, X_train, y_train_sbp, X_test, y_test_sbp, \"SBP\")\n",
    "evaluate_model(rand_forest, X_train, y_train_dbp, X_test, y_test_dbp, \"DBP\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
